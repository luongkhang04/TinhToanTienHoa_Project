% !TEX program = pdflatex
\documentclass[aspectratio=169]{beamer}

% Theme & colors
\usetheme{CambridgeUS}
\usecolortheme{beaver}
\usefonttheme{professionalfonts}

% Encoding & fonts
\usepackage{tabularx}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{lmodern}
\usepackage{graphicx} % For images
\usepackage{booktabs} % For professional tables

% Math
\usepackage{mathrsfs}
\usepackage{amsmath,amssymb,mathtools}
\usepackage{bm}

% Convenience
\newcommand{\E}{\mathbb{E}}
\newcommand{\Var}{\mathrm{Var}}
\newcommand{\Prb}{\mathbb{P}}
\DeclareMathOperator*{\argmax}{arg\,max}

% Metadata
\title[Robot Path Planning]{Robot Path Planning Algorithm}
\subtitle{Yonggang Li, Rencai Jin, Xiangrong Xu, et al.}
\author[Khang Luong, Ong Xuan Son]{Khang Luong, Ong Xuan Son}

\AtBeginSection[]{
    \begin{frame}{Outline}
        \tableofcontents[currentsection]
    \end{frame}
}

\begin{document}

%------------------------------------
\begin{frame}
    \titlepage
\end{frame}

%------------------------------------
\section{Problem Formulation}
%------------------------------------
\begin{frame}{Problem Formulation}

\textbf{Goal:} Plan a safe, smooth, and efficient trajectory for a mobile robot 
from start $S$ to goal $G$ in an environment containing \emph{static} and 
\emph{dynamic} obstacles.

\vspace{0.2cm}

\textbf{Global Planning Problem}
\begin{itemize}
    \item Find a collision-free global path $\pi = \{p_0, p_1, \dots, p_T\}$.
    \item Optimize for: path length, number of turning points, smoothness.
\end{itemize}

\vspace{0.2cm}

\textbf{Local Planning Problem}
\begin{itemize}
    \item Robot state: $q = [x, y, \theta, \phi]^T$ with control input $u = [v, \omega]^T$.
    \item Predict feasible trajectories under kinematic + velocity constraints.
    \item Avoid static \& dynamic obstacles in real time.
\end{itemize}
\end{frame}

%------------------------------------
\section{Related works}
%------------------------------------
\begin{frame}{Improved A* Algorithm}
    The A* algorithm is a heuristic search method for global path planning.
    
    \medskip
    \textbf{Cost Function:}
    The cost of a node $n$ is evaluated by the function:
    \[ f(n) = g(n) + h(n) \]
    $f(n)$: The total estimated cost of the path through node $n$.\\
    $g(n)$: The \textbf{actual cost} from the start node to the current node $n$.\\
    $h(n)$: The \textbf{heuristic estimated cost} from node $n$ to the target node.
\end{frame}

%------------------------------------
\begin{frame}{Improvement 1: Adaptive Step Size}
    To increase flexibility, the algorithm adapts its step size based on the surrounding environment.
    
    \medskip
    \textbf{Threat Function:}
    The obstacle density is quantified by a threat function $f(x_1, x_2)$:
    $$ f(x_1, x_2) = \begin{cases} \frac{1}{k_1 x_1 + k_2 x_2 + c} & \text{if } d=0 \\ 1 & \text{if } d \neq 0 \end{cases} $$
    \begin{itemize}
        \item $x_1, x_2$: The number of static obstacles in immediate and nearby areas, respectively.
        \item $d$: The number of dynamic obstacles in the direction of motion.
        \item $k_1, k_2, c$: Weighting coefficients.
    \end{itemize}
    
    \textbf{Adaptive Step Size Formula:}
    The step length $l$ is then calculated as:
    $$ l = \begin{cases} f(x_1, x_2) \cdot l_{\max} & \text{if } d=0 \\ f(x_1, x_2) \cdot l_{\min} & \text{if } d \neq 0 \end{cases} $$
    This allows the robot to take larger steps in open spaces and smaller, safer steps near obstacles.
\end{frame}

%------------------------------------
\begin{frame}{Improvement 2: Path Smoothing with Bezier Curves}
    \begin{columns}[c]
        \begin{column}{0.6\textwidth}
            \textbf{Cubic Bezier Curve Formula:}
            \begin{itemize}
                \item A curve segment is defined by a start point $P_0$, an end point $P_3$, and two control points $P_1, P_2$.
                \item The coordinates $B(t)$ on the curve at time $t \in [0,1]$ are given by:
            \end{itemize}
            $$ B(t) = (1-t)^{3}P_{0}+3t(1-t)^{2}P_{1}+3t^{2}(1-t)P_{2}+t^{3}P_{3} $$
            This smoothing process ensures the robot can travel smoothly, reducing motor strain and satisfying motion constraints.
        \end{column}
        \begin{column}{0.4\textwidth}
            \begin{figure}
                \includegraphics[width=\textwidth]{images/smooth.jpeg}
            \end{figure}
        \end{column}
    \end{columns}
\end{frame}

%------------------------------------
\begin{frame}{Dynamic Window Approach (DWA)}
    \begin{enumerate}
        \item \textbf{Velocity Sampling:} Sample multiple pairs of linear ($v$) and angular ($\omega$) velocities within a "dynamic window" constrained by motor performance, acceleration limits, and a safe braking distance.
        \item \textbf{Trajectory Simulation:} Predict the robot's trajectory for each sampled velocity pair over a short time interval.
        \item \textbf{Evaluation and Selection:} Use an evaluation function to score valid (non-colliding) trajectories and select the one with the highest score.
    \end{enumerate}
    
    \textbf{DWA Evaluation Function:}
    $$ G(v,\omega)=\sigma[\alpha\cdot head(v,\omega)+\beta\cdot stob(v,\omega) + \delta\cdot dyob(v,\omega)+\gamma\cdot velo(v,\omega)] $$
    $head(v,\omega)$: \textbf{Angular deviation} from the global path.\\
    $stob(v,\omega)$: \textbf{Distance} to the nearest static obstacle.\\
    $dyob(v,\omega)$: \textbf{Distance} to the nearest dynamic obstacle.\\
    $velo(v,\omega)$: The robot's forward \textbf{velocity}.
\end{frame}

%------------------------------------
\begin{frame}{Hybrid Algorithm Performance}
    \textbf{Quantitative Comparison:}
    \begin{table}[h]
        \centering
        \begin{tabular}{lcccc}
            \toprule
            \textbf{Algorithm} & \textbf{Turning} & \textbf{Smoothness} & \textbf{Dynamic Avoid} & \textbf{Path Length} \\
            \midrule
            Traditional A* & 8 & No & No & 14.07 \\
            Improved A* & 6 & Yes & No & 11.92 \\
            DWA & - & Yes & Yes & Not reached \\
            \textbf{Hybrid Algorithm} & \textbf{4} & \textbf{Yes} & \textbf{Yes} & \textbf{13.56} \\
            \bottomrule
        \end{tabular}
        \caption{Performance comparison of the different algorithms.}
    \end{table}
\end{frame}

%------------------------------------
\section{Our proposed method}
%------------------------------------
\begin{frame}{SOO for Continuous Action Selection}

\textbf{Setting}
\[
a = (v,\omega) \in \mathcal{A} 
      = [v_{\min}, v_{\max}] \times 
        [\omega_{\min}, \omega_{\max}], 
\qquad f(a) = G(v,\omega)
\]

\textbf{Goal}
\[
a^{\ast} = \arg\max_{a \in \mathcal{A}} f(a)
\]

\textbf{SOO Search Tree}
\begin{itemize}
  \item Each node $(h,i)$ represents a cell $C_{h,i} \subset \mathcal{A}$
        and a center point $x_{h,i}$.
  \item $\mathcal{T}_t$: tree after $t$ function evaluations.
  \item $\mathcal{L}_t$: leaves of $\mathcal{T}_t$.
\end{itemize}
\end{frame}

%------------------------------------
\begin{frame}{SOO for Continuous Action Selection}
\textbf{Initialization:} 
$\mathcal{T}_1 = \{(0,0)\} \quad\text{(root node)}, \qquad t = 1.$

\textbf{while} True \textbf{do}
\begin{enumerate}
  \item Set $f_{\max} \leftarrow -\infty$.
  
  \item \textbf{for} $h = 0$ to $\min(\mathrm{depth}(\mathcal{T}_t),\, h_{\max}(t))$ \textbf{do}
  
  \begin{enumerate}
      \item Among all leaves $(h,j)\in\mathcal{L}_t$ at depth $h$, select
      $(h,i) \in \arg\max_{(h,j)\in\mathcal{L}_t} f(x_{h,j}).$
      
      \item \textbf{if} $f(x_{h,i}) \ge f_{\max}$ \textbf{then}
      \begin{itemize}
          \item Expand node $(h,i)$:
          add to $\mathcal{T}_t$ the $K$ children  
          $\{(h{+}1,i_1),\dots,(h{+}1,i_K)\}.$
          \item Evaluate $f$ at each new center  
          $\{x_{h+1,i_1},\dots,x_{h+1,i_K}\}.$
          \item Set 
          $f_{\max} = f(x_{h,i}), \qquad t = t + 1.$
          \item \textbf{if} $t = n$ \textbf{then return}
          $x(n) = \arg\max_{(h,i)\in \mathcal{T}_n} f(x_{h,i}).$
      \end{itemize}
      \textbf{end if}
  \end{enumerate}
  
  \textbf{end for}
\end{enumerate}
\textbf{end while}
\end{frame}

%------------------------------------
\begin{frame}{Example of SOO}
\[ f(x)= \frac{\sin(13x)\, \sin(27x) + 1}{2} \]
\begin{figure}
    \includegraphics[width=0.75\textwidth]{images/soo1.png}
\end{figure}
\end{frame}

%------------------------------------
\begin{frame}{Example of SOO}
\[ f(x)= \frac{\sin(13x)\, \sin(27x) + 1}{2} \]
\begin{figure}
    \includegraphics[width=0.75\textwidth]{images/soo2.png}
\end{figure}
\end{frame}

%------------------------------------
\begin{frame}{Example of SOO}
\[ f(x)= \frac{\sin(13x)\, \sin(27x) + 1}{2} \]
\begin{figure}
    \includegraphics[width=0.75\textwidth]{images/soo3.png}
\end{figure}
\end{frame}

%------------------------------------
\begin{frame}{Example of SOO}
\[ f(x_1,x_2) = f(x_1)f(x_2)  \]
\begin{figure}
    \includegraphics[width=0.75\textwidth]{images/soo4.png}
\end{figure}
\end{frame}

%------------------------------------
\begin{frame}{Example of SOO}
\[ f(x_1,x_2) = f(x_1)f(x_2)  \]
\begin{figure}
    \includegraphics[width=0.75\textwidth]{images/soo5.png}
\end{figure}
\end{frame}

%------------------------------------
\begin{frame}{Example of SOO}
\[ f(x_1,x_2) = f(x_1)f(x_2)  \]
\begin{figure}
    \includegraphics[width=0.75\textwidth]{images/soo6.png}
\end{figure}
\end{frame}

%------------------------------------
\begin{frame}{Theoretical Guarantees of SOO}

\textbf{Setting}
\[
f: \mathcal{X} \subset \mathbb{R}^d \to \mathbb{R}, 
\qquad x^\ast = \arg\max_{x\in\mathcal{X}} f(x)
\]

\textbf{Local Smoothness Assumption}
There exists a semi-metric $\ell$ and function $\phi$ such that
\[
f(x^\ast) - f(x) \le \phi\bigl(\ell(x, x^\ast)\bigr),
\]
with $\phi(\varepsilon)\!\to\!0$ as $\varepsilon\!\to\!0$.
(No Lipschitz constant required.)

\textbf{Near-Optimality Dimension} $d^\ast$
\[
d^\ast 
= \inf\bigl\{
d \ge 0 : 
N(\varepsilon)\le C \varepsilon^{-d}
\bigr\},
\]
where $N(\varepsilon)$ is the number of $\varepsilon$-optimal regions.

\textbf{Main SOO Guarantee (Munos, 2011)}
\[
f(x^\ast) - f(x(n))
\le \mathcal{O}\!\left( 
n^{-\frac{1}{d^\ast + 2}}
\right).
\]
\end{frame}

%------------------------------------
\begin{frame}[allowframebreaks]{References}
\begin{thebibliography}{9}
\bibitem{paper} Y. Li, R. Jin, X. Xu, et al., ``Improved A* and Hybrid DWA for Robot Path Planning''.
\bibitem{paper} RÃ©mi Munos, ``From Bandits to Monte-Carlo Tree Search: The Optimistic Principle Applied to Optimization and Planning''.
\end{thebibliography}
\end{frame}

\end{document}