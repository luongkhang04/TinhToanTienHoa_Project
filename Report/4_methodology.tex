\section{METHODOLOGY}

\subsection{System Architecture}

The implemented system employs a \textbf{two-level hierarchical path planning architecture} that combines global strategic planning with local reactive navigation to handle dynamic environments containing moving obstacles. This hierarchical approach decomposes the complex navigation problem into two manageable sub-problems:

\begin{enumerate}
    \item \textbf{Global Planning Layer:} Computes high-level waypoint paths from start to goal using the static map
    \item \textbf{Local Planning Layer:} Performs real-time reactive navigation within the agent's observation range, adapting to moving obstacles
\end{enumerate}

\subsection{Global Path Planning Algorithms}

The global planning layer computes strategic paths through the environment using the complete static map. Four different algorithms have been implemented and evaluated.

\subsubsection{Grid-Based Breadth-First Search (Grid BFS)}

Grid BFS performs a complete breadth-first exploration of the configuration space to find the shortest path in terms of the number of grid cells traversed.

\textbf{Algorithm:}
\begin{enumerate}
    \item Initialize queue with start position
    \item While queue is not empty:
    \begin{itemize}
        \item Dequeue current node
        \item If current node is goal, reconstruct and return path
        \item For each 8-connected neighbor:
        \begin{itemize}
            \item Check if neighbor is free and satisfies safety margin
            \item If not visited, add to queue and record parent
        \end{itemize}
    \end{itemize}
    \item Apply line-of-sight sparsification to reduce waypoints
    \item Push waypoints away from walls to ensure safety margin
\end{enumerate}

\textbf{Key Features:}
\begin{itemize}
    \item Uses 8-connected grid neighborhood (allowing diagonal movements)
    \item Maintains safety margin (default: 2 cells) from obstacles using pre-computed clearance map
    \item Clearance map computed via multi-source BFS from all obstacle cells
    \item Guarantees shortest path if one exists
    \item Time complexity: $O(|V| + |E|)$ where $V$ is the number of free cells
\end{itemize}

\subsubsection{Grid-Based Depth-First Search (Grid DFS)}

Grid DFS explores paths deeply before backtracking, using a stack-based approach to traverse the configuration space.

\textbf{Algorithm:}
\begin{enumerate}
    \item Initialize stack with start position
    \item Initialize visited set
    \item While stack is not empty:
    \begin{itemize}
        \item Pop current node
        \item If current node is goal, reconstruct and return path
        \item For each 8-connected neighbor:
        \begin{itemize}
            \item Check if neighbor is free and satisfies safety margin
            \item If not visited, add to stack, visited set, and record parent
        \end{itemize}
    \end{itemize}
    \item Apply post-processing (sparsification and wall-pushing)
\end{enumerate}

\textbf{Key Features:}
\begin{itemize}
    \item Lower memory footprint compared to BFS in large spaces
    \item Does not guarantee shortest path
    \item Can be faster when goal is "deep" in search tree
    \item Same safety margin enforcement as BFS
\end{itemize}

\subsubsection{A* Search}

A* is an informed search algorithm that uses a heuristic function to guide exploration toward the goal, combining actual cost from start with estimated cost to goal.

\textbf{Cost Function:}
\begin{equation}
f(n) = g(n) + h(n)
\end{equation}

where:
\begin{itemize}
    \item $g(n)$: actual cost from start (1.0 for cardinal moves, 1.414 for diagonal)
    \item $h(n)$: Manhattan distance heuristic to goal: $h(n) = |x_n - x_{goal}| + |y_n - y_{goal}|$
\end{itemize}

\textbf{Algorithm:}
\begin{enumerate}
    \item Initialize priority queue with start node and $f(start) = h(start)$
    \item While priority queue is not empty:
    \begin{itemize}
        \item Extract node with minimum $f$-value
        \item If current node is goal, reconstruct and return path
        \item For each 8-connected neighbor:
        \begin{itemize}
            \item Calculate tentative $g$-score
            \item If better than previous $g$-score:
            \begin{itemize}
                \item Update $g$-score and parent
                \item Calculate $f$-score and add to priority queue
            \end{itemize}
        \end{itemize}
    \end{itemize}
    \item Apply Bresenham line-of-sight sparsification
\end{enumerate}

\textbf{Key Features:}
\begin{itemize}
    \item Uses an 8-connected neighborhood with move costs 1.0 (cardinal) and 1.414 (diagonal)
    \item Heuristic: Manhattan distance $h(n)=|x_n-x_{goal}|+|y_n-y_{goal}|$ (simple goal guidance)
    \item Note: with diagonal moves enabled, Manhattan distance can overestimate the true optimal cost; therefore this implementation is \emph{not guaranteed} to be optimal in all cases
    \item Uses a min-heap (priority queue) for selecting the next node to expand
\end{itemize}

\subsubsection{Dijkstra's Algorithm}

Dijkstra's algorithm finds the shortest path by exploring nodes in order of increasing cost from the start, without using goal-directed heuristics.

\textbf{Algorithm:}
\begin{enumerate}
    \item Initialize distances: $d(start) = 0$, all others to $\infty$
    \item Initialize unvisited set with all free cells
    \item While unvisited set is not empty:
    \begin{itemize}
        \item Select node $u$ with minimum distance from unvisited set
        \item If $u$ is goal, reconstruct and return path
        \item Remove $u$ from unvisited set
        \item For each neighbor $v$ of $u$:
        \begin{itemize}
            \item Calculate new distance: $d_{new} = d(u) + cost(u,v)$
            \item If $d_{new} < d(v)$, update $d(v)$ and parent
        \end{itemize}
    \end{itemize}
\end{enumerate}

\textbf{Key Features:}
\begin{itemize}
    \item Guarantees optimal path (shortest in terms of actual distance)
    \item Edge costs: 1.0 for cardinal, 1.414 for diagonal movements
    \item More thorough but slower than A* for single-goal queries
    \item Implementation detail: selects the minimum-distance unvisited node via a linear scan over an unvisited set (i.e., no priority queue), giving worst-case time complexity $O(|V|^2)$
\end{itemize}

\subsection{Path Optimization Techniques}

Several optimization techniques are applied to improve path quality:

\subsubsection{Clearance Map Computation}

A clearance map is pre-computed using multi-source BFS to determine the distance from each free cell to the nearest obstacle:

\begin{enumerate}
    \item Initialize all obstacle cells with distance 0 and add to queue
    \item For each cell in queue, propagate distance to 8-connected neighbors
    \item Result: each cell contains Chebyshev distance to nearest obstacle
\end{enumerate}

This map enables efficient safety margin enforcement during planning.

\subsubsection{Line-of-Sight Sparsification}

The Bresenham line algorithm is used to reduce waypoint count:

\begin{enumerate}
    \item Start with first waypoint as anchor
    \item Find furthest waypoint visible from anchor (no obstacles on line)
    \item Add this waypoint to sparse path and set as new anchor
    \item Repeat until goal is reached
\end{enumerate}

This reduces the dense cell-by-cell paths to sparse waypoint sequences.

\subsubsection{Wall-Pushing Strategy}

Waypoints are adjusted to maintain safety margin from obstacles:

\begin{enumerate}
    \item For each waypoint, check if clearance exceeds margin
    \item If insufficient clearance, search local neighborhood
    \item Select nearby cell with maximum clearance
    \item Replace waypoint with safer alternative
\end{enumerate}

\subsection{Local Path Planning Algorithms}

The local planning layer handles real-time reactive navigation within the agent's observation range. Six reactive strategies have been implemented.

\subsubsection{Reactive BFS Planner}

Performs BFS within the agent's local observation window to find collision-free paths to the current waypoint.

\textbf{Agent Graph Construction:}
\begin{enumerate}
    \item Define observation window: $[x_a - r, x_a + r] \times [y_a - r, y_a + r]$
    \item For each observed obstacle, inflate by safety margin using Chebyshev distance
    \item Create state space of free cells within observation
    \item Build adjacency graph using 4-connected moves (UP/DOWN/LEFT/RIGHT). A \texttt{NONE} action exists but does not expand the search.
\end{enumerate}

\textbf{Waypoint Projection:}
When global waypoint falls outside observation or in inflated obstacles:
\begin{enumerate}
    \item Find all free cells in observation
    \item Compute Euclidean distance from each to waypoint
    \item Select cell with minimum distance as projected goal
\end{enumerate}

\textbf{Path Computation:}
\begin{enumerate}
    \item Apply BFS on agent graph from current position to projected waypoint
    \item Extract next step from computed path
    \item Convert to action vector (movement direction)
\end{enumerate}

\textbf{Key Features:}
\begin{itemize}
    \item Fast replanning in constrained local space
    \item Guaranteed to find path in local observation if one exists
    \item Adapts to moving obstacles via observation updates
    \item Time complexity: $O(r^2)$ in the size of the observation window (roughly $(2r+1)^2$ cells)
\end{itemize}

\subsubsection{Reactive DFS Planner}

Uses depth-first search strategy for local navigation, exploring paths deeply before backtracking.

\textbf{Algorithm:}
\begin{enumerate}
    \item Build agent graph with inflated obstacles
    \item Apply recursive DFS from current position to projected waypoint
    \item Return first found path (not necessarily shortest)
    \item Track stuck counter to detect navigation failures
\end{enumerate}

\textbf{Key Features:}
\begin{itemize}
    \item Lower memory usage than BFS in local space
    \item Can find alternative paths in environments with multiple routes
    \item Useful when multiple similar-length paths exist
    \item May explore longer paths before finding goal
\end{itemize}

\subsubsection{Potential Field Planner}

Models navigation as moving under artificial forces: attractive force toward goal and repulsive forces from obstacles.

\textbf{Force Model:}
\begin{equation}
\vec{F}_{total} = \vec{F}_{attractive} + \vec{F}_{repulsive}
\end{equation}

\textbf{Attractive Force:}
\begin{equation}
\vec{F}_{attractive} = k_a \cdot \frac{\vec{d}_{goal}}{||\vec{d}_{goal}||}
\end{equation}

where $k_a$ is attraction weight (default: 1.0) and $\vec{d}_{goal}$ is the direction vector to the goal.

\textbf{Repulsive Force:}
\begin{equation}
\vec{F}_{repulsive} = \sum_{i \in obstacles} k_r \cdot \frac{\vec{d}_{away,i}}{||\vec{d}_{away,i}||}
\end{equation}

where $k_r$ is repulsion weight (default: 2.0), computed for all obstacles within repulsion range (default: 3 cells).

\textbf{Force-to-Action Conversion:}
\begin{enumerate}
    \item Compute total force vector
    \item Determine dominant direction (horizontal vs. vertical)
    \item Map to a \textbf{4-connected} discrete action: UP, DOWN, LEFT, or RIGHT (no diagonal actions in this planner)
    \item Treat cells that violate the clearance margin as obstacles (repulsion is computed against the \emph{inflated} free-space constraint)
\end{enumerate}

\textbf{Key Features:}
\begin{itemize}
    \item Smooth, reactive behavior without explicit path search
    \item Naturally avoids obstacles through repulsive forces
    \item Can suffer from local minima in complex configurations
    \item Computationally efficient: $O(r^2)$ for force computation
    \item No memory overhead for graph structures
\end{itemize}

\subsubsection{Greedy Local Planner}

Selects actions that maximize progress toward the goal while avoiding obstacles using a simple greedy heuristic.

\textbf{Algorithm:}
\begin{enumerate}
    \item Calculate current distance to goal: $d_{current} = ||\vec{goal} - \vec{current}||$
    \item For each of 8 possible actions (cardinal + diagonal):
    \begin{itemize}
        \item Compute next position
        \item Check validity (within global bounds, within the current observation window, not an obstacle, and satisfies clearance margin)
        \item Calculate new distance to goal: $d_{new}$
        \item If $d_{new} < d_{current}$, select this action
    \end{itemize}
    \item If no improving action found, increment stuck counter
\end{enumerate}

\textbf{Key Features:}
\begin{itemize}
    \item Simple and computationally efficient: $O(1)$ per step
    \item No memory overhead (no graph or queue structures)
    \item Works well in open spaces with sparse obstacles
    \item Can get trapped in local minima or dead ends
    \item Myopic decision-making without lookahead
\end{itemize}

\subsubsection{Dynamic Window Approach (DWA) Planner}

Implements a \textbf{grid-adapted Dynamic Window Approach} that samples discrete velocity commands and selects the action that best balances goal progress, obstacle clearance, and speed.

\textbf{Dynamic Window Sampling:}
At each time step, candidate velocities $\vec{v}=(v_x, v_y)$ are generated from a bounded window around the previous action $\vec{v}_{t-1}$:
\begin{equation}
v_x \in [v_{x,t-1}-a_{max},\, v_{x,t-1}+a_{max}], \quad
v_y \in [v_{y,t-1}-a_{max},\, v_{y,t-1}+a_{max}], \quad
\max(|v_x|,|v_y|)\le v_{max}
\end{equation}

\textbf{Trajectory Prediction and Feasibility:}
For each candidate $\vec{v}$, a short trajectory is simulated with constant velocity for $N$ prediction steps:
\begin{equation}
\vec{p}_k = \vec{p}_0 + k\vec{v}, \quad k=1,\dots,N
\end{equation}
The candidate is rejected if any predicted position violates global bounds or the local \emph{inflated} obstacle constraint (clearance $\le m$). Prediction is truncated once the simulated state leaves the current observation window.

\textbf{Scoring Function:}
Each feasible candidate is scored by a weighted sum:
\begin{equation}
J(\vec{v}) = w_h \, S_{heading} + w_c \, S_{clearance} + w_s \, S_{speed}
\end{equation}
where:
\begin{itemize}
    \item $S_{heading} = \frac{1}{\|\vec{p}_{final}-\vec{p}_{goal}\|+1}$ (Euclidean goal proximity)
    \item $S_{clearance} = \frac{\min(c_{min}, c_{cap})}{c_{cap}}$, with $c_{min}$ the minimum local clearance along the trajectory
    \item $S_{speed} = \frac{\|\vec{v}\|}{v_{max}}$
\end{itemize}
The selected local action is the $\vec{v}$ that maximizes $J(\vec{v})$.

\textbf{Key Features:}
\begin{itemize}
    \item Incorporates short-horizon lookahead while remaining reactive
    \item Acceleration-limited sampling yields smoother action changes across steps
    \item Explicitly trades off goal progress vs. obstacle clearance via weights
    \item Computationally light due to small discrete candidate set
\end{itemize}

\subsubsection{Rolling-Horizon Evolutionary Local Planner}

Implements a \textbf{rolling-horizon evolutionary algorithm} that optimizes a short discrete action sequence and executes only the first action, replanning at every step.

\textbf{Action Representation:}
Plans are sequences $\pi = (a_0,\dots,a_{H-1})$ of horizon length $H$, where each $a_i$ is chosen from a 5-action set (4-connected moves + \texttt{NONE}).

\textbf{Population Initialization:}
\begin{enumerate}
    \item Optionally seed one individual using the local BFS path converted into an action sequence
    \item Generate the remaining individuals by sampling valid actions, with a \emph{goal bias} that prefers actions reducing Manhattan distance to the projected waypoint
\end{enumerate}

\textbf{Sequence Evaluation:}
Each sequence is simulated from the current state. A sequence is invalid (discarded) if it exits global bounds or enters an inflated obstacle cell within the observation window. The fitness is a weighted cost that combines:
\begin{itemize}
    \item Final and best-achieved Manhattan distance to goal (goal-reaching pressure)
    \item Average distance-to-goal over the horizon (path efficiency)
    \item Penalties for moving away from the goal and for a non-improving first step (stuck avoidance)
    \item Clearance cost accumulated as $\sum \frac{1}{c+1}$ for observed steps (risk sensitivity)
    \item Turn count and \texttt{NONE} (stall) count (action smoothness and progress)
    \item Steps outside observation (unknown-space penalty)
\end{itemize}

\textbf{Cost Formulation:}
Let $\vec{p}_0=(x_0,y_0)$ be the current state, goal $\vec{g}=(x_g,y_g)$, and simulated rollout
$\vec{p}_{t+1}=\vec{p}_t + a_t$ for $t=0,\dots,H-1$. Define the Manhattan distance at step $t$:
\begin{equation}
d_t = |x_t - x_g| + |y_t - y_g|
\end{equation}
with derived terms:
\begin{align}
d_{final} &= d_H, \qquad d_{min} = \min_{1 \le t \le H} d_t, \qquad \bar{d} = \frac{1}{H}\sum_{t=1}^{H} d_t
\end{align}
The penalties used in the implementation are:
\begin{align}
P_{inc} &= \sum_{t=1}^{H} \max(0, d_t - d_{t-1}) \\
P_{fs} &=
\begin{cases}
0, & d_1 < d_0 \\
(d_1 - d_0) + 1, & d_1 \ge d_0
\end{cases} \\
T &= \sum_{t=1}^{H-1} \mathbb{I}[a_{t-1} \neq \texttt{NONE} \wedge a_t \neq \texttt{NONE} \wedge a_{t-1} \neq a_t] \\
S &= \sum_{t=0}^{H-1} \mathbb{I}[a_t = \texttt{NONE}] \\
U &= \sum_{t=1}^{H} \mathbb{I}[\vec{p}_t \notin \Omega_{obs}] \\
C &= \sum_{t=1}^{H} \mathbb{I}[\vec{p}_t \in \Omega_{obs}] \cdot \frac{1}{c_t + 1}
\end{align}
where $\Omega_{obs}$ is the current observation window and $c_t$ is the local clearance value (Chebyshev distance to the nearest observed obstacle) at $\vec{p}_t$. The total sequence cost is:
\begin{equation}
J(\pi)= w_g(0.7 d_{final} + 0.3 d_{min}) + w_{step}\bar{d} + w_{inc}P_{inc} + w_{fs}P_{fs} + w_{clr}C + w_{turn}T + w_{stall}S + w_{unk}U
\end{equation}
Weights $\{w_\cdot\}$ correspond to the tunable parameters \texttt{goal\_weight}, \texttt{step\_weight}, \texttt{increase\_weight}, \texttt{first\_step\_weight}, \texttt{clearance\_weight}, \texttt{turn\_weight}, \texttt{stall\_weight}, and \texttt{unknown\_weight}.
Lower cost corresponds to better sequences.

\textbf{Evolutionary Update:}
\begin{enumerate}
    \item Keep an elite fraction of the best sequences
    \item Generate the remaining population using tournament selection, single-point crossover, and mutation
    \item After a fixed number of generations, select the best sequence and execute its first action
\end{enumerate}

\textbf{Key Features:}
\begin{itemize}
    \item Lookahead-based local planning that can escape greedy local minima
    \item BFS seeding provides a strong baseline when a local path exists
    \item Penalizes unknown regions while still allowing boundary exploration
    \item Replans each step, enabling adaptation to moving obstacles
\end{itemize}

\subsection{Integration and Coordination}

The hierarchical system coordinates global and local planning through several mechanisms:

\subsubsection{Waypoint Following}

\begin{enumerate}
    \item Local planner maintains current waypoint index in global path
    \item Projects current waypoint into local observation space
    \item Executes local plan to reach projected waypoint
    \item When waypoint reached (within a small tolerance), advances to next waypoint
    \item Repeats until final goal is reached
\end{enumerate}

\subsubsection{Stuck Detection and Recovery}

To handle situations where the agent cannot make progress, the execution loop tracks both \emph{no-motion} and \emph{no-progress} events:

\begin{enumerate}
    \item Monitor agent position changes across time steps, and whether distance to the \emph{current waypoint} decreases
    \item Increment stuck counter when the agent does not move, or when the Manhattan distance to the current waypoint does not decrease
    \item When stuck counter exceeds a threshold (typically 15--20 steps depending on the execution script):
    \begin{itemize}
        \item Trigger global replanning from current position
        \item Compute new waypoint sequence to final goal
        \item Reset waypoint index and stuck counter
        \item Resume local planning with new global path
    \end{itemize}
\end{enumerate}

\subsubsection{Observation Updates}

After each action execution:

\begin{enumerate}
    \item Agent moves to new position
    \item Observe environment within sensing range
    \item Detect obstacle positions (static and moving)
    \item Reconstruct agent graph with updated observations
    \item Inflate newly detected obstacles by safety margin (Chebyshev radius)
    \item Continue local planning with updated graph
\end{enumerate}

\subsubsection{Safety Margin Enforcement}

Consistent safety enforcement across both layers:

\begin{itemize}
    \item \textbf{Global layer:} Pre-computes clearance map over entire environment using multi-source BFS with Chebyshev distance metric
    \item \textbf{Local layer:} Computes local clearance map within observation window for each update
    \item \textbf{Coordination:} Both layers enforce a configurable margin; in the provided runner/benchmark setup the global margin is typically 2 cells while the local inflation margin is set to 1 cell
    \item \textbf{Obstacle inflation:} Chebyshev ball of radius $m$ around each obstacle cell
\end{itemize}

\subsection{Algorithm Comparison Framework}

The implementation provides a flexible framework for comparative evaluation of different algorithm combinations.

\subsubsection{Configurable Parameters}

\begin{itemize}
    \item \textbf{Global planner:} \texttt{grid\_bfs}, \texttt{grid\_dfs}, \texttt{astar}, \texttt{dijkstra}
    \item \textbf{Local planner:} \texttt{reactive\_bfs}, \texttt{reactive\_dfs}, \texttt{potential\_field}, \texttt{greedy}, \texttt{dwa}, \texttt{evolutionary}
    \item \textbf{Number of moving obstacles:} Configurable (default: 100 in the demo runner; benchmark evaluates $\{0, 50, 100, 200\}$)
    \item \textbf{Safety margin:} Configurable clearance from obstacles (global typically 2; local inflation typically 1)
    \item \textbf{Agent sensing range:} Observation window radius (default: 2 cells)
    \item \textbf{Map selection:} Multiple test environments (maps 1-7)
\end{itemize}

\subsubsection{Performance Metrics}

The system measures the following metrics for evaluation:

\begin{itemize}
    \item \textbf{Global planning time:} Time to compute initial waypoint path (seconds)
    \item \textbf{Total execution steps:} Number of discrete time steps to reach goal
    \item \textbf{Path length:} Total number of cells traversed in complete path
    \item \textbf{Success rate:} Goal reached vs. maximum step limit (1000 steps)
    \item \textbf{Replanning frequency:} Number of stuck detections requiring global replanning
\end{itemize}
